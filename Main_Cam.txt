import cv2
import mediapipe as mp
import numpy as np
import math
from math import *

# Inicializa las bibliotecas de MediaPipe para la mano y la pose del cuerpo
mp_hands = mp.solutions.hands
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# Inicializa la captura de video desde la cámara
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)

# Pulgar
thumb_points = [1, 2, 4]

# Índice, medio, anular y meñique
palm_points = [0, 1, 2, 5, 9, 13, 17]
fingertips_points = [8, 12, 16, 20]
finger_base_points = [6, 10, 14, 18]

# Colores
GREEN = (48, 255, 48)
BLUE = (192, 101, 21)
YELLOW = (0, 204, 255)
PURPLE = (128, 64, 128)
PEACH = (180, 229, 255)
RED = (0, 0, 255)

# Inicializa el modelo de detección de pose de cuerpo completo y de manos
with mp_pose.Pose(
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as pose, mp_hands.Hands(
        model_complexity=1,
        max_num_hands=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as hands:

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.flip(frame, 1)
        height, width, _ = frame.shape
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Realiza la detección de pose en el cuadro actual
        pose_results = pose.process(frame_rgb)
        fingers_counter = "_"
        thickness = [2, 2, 2, 2, 2]

        if pose_results.pose_landmarks:
            # Extrae el landmark de la cabeza (nariz)
            head_landmark = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE]

            # Dibuja un círculo en el punto de la cabeza (nariz)
            cv2.circle(frame, (int(head_landmark.x * width), int(head_landmark.y * height)), 5, RED, -1)

            # Extrae los landmarks del pulgar derecho y la muñeca izquierda
            left_thumb = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_THUMB]
            left_wrist = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]

            # Convierte las coordenadas normalizadas en coordenadas de píxeles
            left_thumb_x = int(left_thumb.x * width)
            left_thumb_y = int(left_thumb.y * height)
            left_wrist_x = int(left_wrist.x * width)
            left_wrist_y = int(left_wrist.y * height)

            # Dibuja un círculo en el pulgar derecho
            #cv2.circle(frame, (left_thumb_x, left_thumb_y), 5, GREEN, -1)
            #cv2.putText(frame, "left Thumb", (left_thumb_x, left_thumb_y), 1, 1, (255, 255, 255), 2)

            # Dibuja un círculo en la muñeca izquierda
            #cv2.circle(frame, (left_wrist_x, left_wrist_y), 5, BLUE, -1)
            #cv2.putText(frame, "Left Wrist", (left_wrist_x, left_wrist_y), 1, 1, (255, 255, 255), 2)

        # Realiza la detección de la mano en el cuadro actual
        hand_results = hands.process(frame_rgb)

        if hand_results.multi_hand_landmarks:
            # Obtén la primera mano detectada (debería ser la mano derecha)
            hand_landmarks = hand_results.multi_hand_landmarks[0]

            coordinates_thumb = []
            coordinates_palm = []
            coordinates_ft = []
            coordinates_fb = []

            for index in thumb_points:
                x = int(hand_landmarks.landmark[index].x * width)
                y = int(hand_landmarks.landmark[index].y * height)
                coordinates_thumb.append([x, y])

            for index in palm_points:
                x = int(hand_landmarks.landmark[index].x * width)
                y = int(hand_landmarks.landmark[index].y * height)
                coordinates_palm.append([x, y])

            for index in fingertips_points:
                x = int(hand_landmarks.landmark[index].x * width)
                y = int(hand_landmarks.landmark[index].y * height)
                coordinates_ft.append([x, y])

            for index in finger_base_points:
                x = int(hand_landmarks.landmark[index].x * width)
                y = int(hand_landmarks.landmark[index].y * height)
                coordinates_fb.append([x, y])

            # Pulgar
            p1 = np.array(coordinates_thumb[0])
            p2 = np.array(coordinates_thumb[1])
            p3 = np.array(coordinates_thumb[2])

            l1 = np.linalg.norm(p2 - p3)
            l2 = np.linalg.norm(p1 - p3)
            l3 = np.linalg.norm(p1 - p2)

            # Calcular el ángulo
            if -1 <= (l1 ** 2 + l3 ** 2 - l2 ** 2) / (2 * l1 * l3) <= 1:
                angle = degrees(acos((l1 ** 2 + l3 ** 2 - l2 ** 2) / (2 * l1 * l3)))
            else:
                angle = 0  # O establece un valor predeterminado cuando los valores están fuera del rango válido
            thumb_finger = np.array(False)
            if angle > 150:
                thumb_finger = np.array(True)

            # Distancias
            coordinates_head = np.array([head_landmark.x * width, head_landmark.y * height])
            coordinates_ft = np.array(coordinates_ft)
            coordinates_fb = np.array(coordinates_fb)

            # Distancias desde la cabeza (nariz) a los puntos de los dedos
            d_head_ft = np.linalg.norm(coordinates_head - coordinates_ft, axis=1)
            d_head_fb = np.linalg.norm(coordinates_head - coordinates_fb, axis=1)
            dif = d_head_ft - d_head_fb
            fingers = dif > 0
            fingers = np.append(thumb_finger, fingers)
            fingers_counter = str(np.count_nonzero(fingers == True))
            for (i, finger) in enumerate(fingers):
                if finger == True:
                    thickness[i] = -1

            # Dibuja una línea desde la cabeza (nariz) hasta la base del pulgar
            cv2.line(frame, (int(head_landmark.x * width), int(head_landmark.y * height)),
                    (coordinates_thumb[1][0], coordinates_thumb[1][1]), (255, 0, 0), 2)

            # Dibuja una linea desde la cabeza (nariz) hasta la base del meñique
            cv2.line(frame, (int(head_landmark.x * width), int(head_landmark.y * height)),
                    (coordinates_palm[6][0], coordinates_palm[6][1]), (0, 0, 255), 2)
            
            cv2.line(frame, (coordinates_thumb[1][0], coordinates_thumb[1][1]),
                    (coordinates_palm[6][0], coordinates_palm[6][1]), (0, 0, 255), 2)

            # Calcula la distancia entre las nuevas líneas y la cabeza (nariz)
            distance_head_thumb = np.linalg.norm(
                [head_landmark.x * width, head_landmark.y * height] - np.array(coordinates_thumb[1]))
            distance_head_pink_tip = np.linalg.norm(
                [head_landmark.x * width, head_landmark.y * height] - np.array(coordinates_palm[6]))
            
            initial_distance = 140.0
            # Calcula la distancia entre los puntos de interés
            current_distance = np.linalg.norm(
                np.array([coordinates_thumb[1][0], coordinates_thumb[1][1]]) -
                np.array([coordinates_palm[6][0], coordinates_palm[6][1]])
            )
            
            if current_distance > initial_distance:
                # Calcula la rotación en grados
                
                rotation_degrees = math.degrees(math.asin((current_distance - initial_distance) / initial_distance))
            else:
                rotation_degrees = -math.degrees(math.asin((initial_distance - current_distance) / initial_distance))

                # Luego, puedes mostrar la distancia en la ventana de visualización
                cv2.putText(frame, f'DISTANCIA: {current_distance:.2f}', (100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1,
                            (0, 255, 0), 2)



            # Calcula la distancia promedio entre ambos puntos
            #distance_prom = distance_head_thumb - distance_head_pink_tip
            #cv2.putText(frame, f'DISTANCIA MANOS: {distance_prom:.2f}', (100, 120), cv2.FONT_HERSHEY_SIMPLEX, 1,
            #            (0, 255, 0), 2)

            if distance_head_thumb > distance_head_pink_tip:
                cv2.putText(frame, "girando mano", (420, 80), 1, 1, (255, 255, 255), 2)

            mp_drawing.draw_landmarks(
                frame,
                hand_landmarks,
                mp_hands.HAND_CONNECTIONS,
                mp_drawing_styles.get_default_hand_landmarks_style(),
                mp_drawing_styles.get_default_hand_connections_style())

        # Visualización
        cv2.rectangle(frame, (0, 0), (80, 80), (125, 220, 0), -1)
        cv2.putText(frame, fingers_counter, (15, 65), 1, 5, (255, 255, 255), 2)
        # Pulgar
        cv2.rectangle(frame, (100, 10), (150, 60), PEACH, thickness[0])
        cv2.putText(frame, "Pulgar", (100, 80), 1, 1, (255, 255, 255), 2)
        # Índice
        cv2.rectangle(frame, (160, 10), (210, 60), PURPLE, thickness[1])
        cv2.putText(frame, "Indice", (160, 80), 1, 1, (255, 255, 255), 2)
        # Medio
        cv2.rectangle(frame, (220, 10), (270, 60), YELLOW, thickness[2])
        cv2.putText(frame, "Medio", (220, 80), 1, 1, (255, 255, 255), 2)
        # Anular
        cv2.rectangle(frame, (280, 10), (330, 60), GREEN, thickness[3])
        cv2.putText(frame, "Anular", (280, 80), 1, 1, (255, 255, 255), 2)
        # Menique
        cv2.rectangle(frame, (340, 10), (390, 60), BLUE, thickness[4])
        cv2.putText(frame, "Menique", (340, 80), 1, 1, (255, 255, 255), 2)

        # Muestra el cuadro de video
        cv2.imshow("Hand and Body Pose Detection", frame)
        # Detiene el bucle cuando se presiona la tecla 'q'
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

# Libera la captura de video y cierra la ventana
cap.release()
cv2.destroyAllWindows()
